{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Model Training - ResNet50, ResNet152V2, VGG16, InceptionV3 etc..ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinethRubeh/Cotton-Disease-Prediction/blob/master/Model_Training_ResNet50%2C_ResNet152V2%2C_VGG16%2C_InceptionV3_etc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSB7eUZX56US",
        "outputId": "a2c9aefc-bcbe-4c5f-847d-888e313c6ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur693lX16Ne7",
        "outputId": "41a55d25-63cf-4c83-ec40-404fd7d0f306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmWR1zMf6Oyo",
        "outputId": "80630f09-7fc2-4006-bcf1-73c01b720816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct  1 19:05:23 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    30W /  70W |    755MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vXCKenX6O6R"
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuJ02CSfwW8E",
        "outputId": "e276c18c-7b91-4f16-daa2-cbf8ff11b278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.2.0 in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (50.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXuBQAoQgRf-",
        "outputId": "2cdc48a2-656c-4044-84dc-d074ca0db92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY4sY9GsgRgE"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IumSycPqgRgI"
      },
      "source": [
        "# Resize images\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "image_size = [img_height, img_width, 3] # height, width, depth\n",
        "\n",
        "# Output classes\n",
        "predict_class_size = 4\n",
        "\n",
        "# batch size\n",
        "bs = 32\n",
        "\n",
        "# Train/test image path\n",
        "train_dir = '/content/drive/My Drive/google colab/cotton_data/train'\n",
        "test_dir = '/content/drive/My Drive/google colab/cotton_data/val'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQOHHPaSgRgM"
      },
      "source": [
        "model_dict = {VGG19:\"vgg19\", ResNet152V2:\"resnet152v2\", InceptionV3:\"inceptionv3\"}\n",
        "# ResNet152V2:\"resnet152v2\", VGG19:\"vgg19\", InceptionV3:\"inceptionv3\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSo67lJ7gRgQ"
      },
      "source": [
        "def plot_loss_acc(model_history, model_name):\n",
        "    \n",
        "    ## Plot loss\n",
        "    plt.plot(model_history.history['loss'], label='train loss')\n",
        "    plt.plot(model_history.history['val_loss'], label='test loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/drive/My Drive/google colab/cotton_data/models/loss_{}'.format(model_name))\n",
        "    plt.clf()\n",
        "\n",
        "    ## Plot Accuracy\n",
        "    plt.plot(model_history.history['accuracy'], label='train accuracy')\n",
        "    plt.plot(model_history.history['val_accuracy'], label='test accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/drive/My Drive/google colab/cotton_data/models/accuracy_{}'.format(model_name))\n",
        "    plt.clf()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r48Uy-OvgRgV"
      },
      "source": [
        "def train_model(pre_trained_model):\n",
        "    \n",
        "    # Intialize pre trained model (ResNet152V2, VGG19, InceptionV3) with imagenet weights\n",
        "    pre_trained_net = pre_trained_model(input_shape=image_size, weights='imagenet', include_top=False)\n",
        "\n",
        "    # Freeze model weights (don't train)\n",
        "    for layer in pre_trained_net.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # layers\n",
        "    x = Flatten()(pre_trained_net.output)\n",
        "\n",
        "    # output layer\n",
        "    pred_layer = Dense(predict_class_size, activation='softmax')(x)\n",
        "    \n",
        "    # create model object\n",
        "    model = Model(inputs=pre_trained_net.input, outputs=pred_layer)\n",
        "\n",
        "    # Model structure\n",
        "    # model.summary()\n",
        "\n",
        "    # Set cost and optimization functions for model\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer='adam', \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Image Data Augmentation using keras ImageDataGenerator\n",
        "    # train data generator\n",
        "    train_aug = ImageDataGenerator(rescale=1/255, \n",
        "                                   rotation_range=10, \n",
        "#                                    width_shift_range=0.2, # horizontal shift\n",
        "#                                    height_shift_range=0.2, # vertical shift\n",
        "#                                    horizontal_flip=True, \n",
        "#                                    vertical_flip=True, \n",
        "                                   zoom_range=0.2, # ~ [1-0.2, 1+0.2]\n",
        "                                   brightness_range=[0.5,1.5]) # <1 darkens img, >1 brightens img\n",
        "    # test data generator\n",
        "    test_aug = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "    # Create train/test set\n",
        "    train_set = train_aug.flow_from_directory(train_dir, \n",
        "                                              target_size=(img_height,img_width), \n",
        "                                              batch_size=bs, \n",
        "                                              class_mode='categorical')\n",
        "\n",
        "    test_set = test_aug.flow_from_directory(test_dir, \n",
        "                                            target_size=(img_height,img_width), \n",
        "                                            batch_size=bs, \n",
        "                                            class_mode='categorical')\n",
        "\n",
        "    # fit the model\n",
        "    hist = model.fit_generator(train_set, \n",
        "                              epochs=20,\n",
        "                              steps_per_epoch=len(train_set),\n",
        "                              validation_data=test_set,\n",
        "                              validation_steps=len(test_set)\n",
        "                             )\n",
        "    \n",
        "    # model name\n",
        "    model_name = model_dict[pre_trained_model]\n",
        "    \n",
        "    # Save model loss/accuracy plots\n",
        "    plot_loss_acc(hist,model_name)\n",
        "    \n",
        "    # Save model\n",
        "    model.save('/content/drive/My Drive/google colab/cotton_data/models/model_{}.h5'.format(model_name))\n",
        "    \n",
        "    print(\"model {} trained and saved\".format(model_name))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyYXLwi9gRgZ",
        "outputId": "352d8b6b-1cba-4392-a3fc-b9317607cc1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for each_model in list(model_dict.keys()):\n",
        "    train_model(each_model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Found 1951 images belonging to 4 classes.\n",
            "Found 324 images belonging to 4 classes.\n",
            "Epoch 1/20\n",
            "61/61 [==============================] - 648s 11s/step - loss: 0.9215 - accuracy: 0.6873 - val_loss: 0.4847 - val_accuracy: 0.8364\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 41s 678ms/step - loss: 0.3229 - accuracy: 0.8821 - val_loss: 0.3013 - val_accuracy: 0.8765\n",
            "Epoch 3/20\n",
            "61/61 [==============================] - 42s 682ms/step - loss: 0.2446 - accuracy: 0.9134 - val_loss: 0.3123 - val_accuracy: 0.8735\n",
            "Epoch 4/20\n",
            "61/61 [==============================] - 42s 684ms/step - loss: 0.1897 - accuracy: 0.9344 - val_loss: 0.2115 - val_accuracy: 0.9198\n",
            "Epoch 5/20\n",
            "61/61 [==============================] - 42s 694ms/step - loss: 0.1800 - accuracy: 0.9390 - val_loss: 0.2977 - val_accuracy: 0.8981\n",
            "Epoch 6/20\n",
            "61/61 [==============================] - 42s 685ms/step - loss: 0.1440 - accuracy: 0.9559 - val_loss: 0.2260 - val_accuracy: 0.8858\n",
            "Epoch 7/20\n",
            "61/61 [==============================] - 42s 687ms/step - loss: 0.1410 - accuracy: 0.9549 - val_loss: 0.2560 - val_accuracy: 0.9012\n",
            "Epoch 8/20\n",
            "61/61 [==============================] - 42s 681ms/step - loss: 0.1056 - accuracy: 0.9713 - val_loss: 0.2534 - val_accuracy: 0.8827\n",
            "Epoch 9/20\n",
            "61/61 [==============================] - 42s 687ms/step - loss: 0.1110 - accuracy: 0.9600 - val_loss: 0.1526 - val_accuracy: 0.9383\n",
            "Epoch 10/20\n",
            "61/61 [==============================] - 42s 686ms/step - loss: 0.1022 - accuracy: 0.9631 - val_loss: 0.1724 - val_accuracy: 0.9136\n",
            "Epoch 11/20\n",
            "61/61 [==============================] - 42s 681ms/step - loss: 0.0933 - accuracy: 0.9672 - val_loss: 0.2339 - val_accuracy: 0.8858\n",
            "Epoch 12/20\n",
            "61/61 [==============================] - 42s 694ms/step - loss: 0.0813 - accuracy: 0.9739 - val_loss: 0.2614 - val_accuracy: 0.8858\n",
            "Epoch 13/20\n",
            "61/61 [==============================] - 42s 684ms/step - loss: 0.0791 - accuracy: 0.9780 - val_loss: 0.1849 - val_accuracy: 0.9105\n",
            "Epoch 14/20\n",
            "61/61 [==============================] - 42s 686ms/step - loss: 0.0805 - accuracy: 0.9733 - val_loss: 0.2651 - val_accuracy: 0.8827\n",
            "Epoch 15/20\n",
            "61/61 [==============================] - 42s 681ms/step - loss: 0.0787 - accuracy: 0.9744 - val_loss: 0.1392 - val_accuracy: 0.9506\n",
            "Epoch 16/20\n",
            "61/61 [==============================] - 42s 680ms/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.1989 - val_accuracy: 0.9259\n",
            "Epoch 17/20\n",
            "61/61 [==============================] - 41s 677ms/step - loss: 0.0608 - accuracy: 0.9815 - val_loss: 0.1873 - val_accuracy: 0.9136\n",
            "Epoch 18/20\n",
            "61/61 [==============================] - 42s 684ms/step - loss: 0.0778 - accuracy: 0.9708 - val_loss: 0.1711 - val_accuracy: 0.9414\n",
            "Epoch 19/20\n",
            "61/61 [==============================] - 42s 687ms/step - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.1276 - val_accuracy: 0.9475\n",
            "Epoch 20/20\n",
            "61/61 [==============================] - 42s 682ms/step - loss: 0.0484 - accuracy: 0.9872 - val_loss: 0.1986 - val_accuracy: 0.9198\n",
            "model vgg19 trained and saved\n",
            "Found 1951 images belonging to 4 classes.\n",
            "Found 324 images belonging to 4 classes.\n",
            "Epoch 1/20\n",
            "61/61 [==============================] - 46s 754ms/step - loss: 1.4768 - accuracy: 0.8083 - val_loss: 0.4107 - val_accuracy: 0.9383\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 43s 704ms/step - loss: 0.4303 - accuracy: 0.9334 - val_loss: 0.2996 - val_accuracy: 0.9475\n",
            "Epoch 3/20\n",
            "61/61 [==============================] - 43s 706ms/step - loss: 0.3209 - accuracy: 0.9528 - val_loss: 0.7078 - val_accuracy: 0.9290\n",
            "Epoch 4/20\n",
            "61/61 [==============================] - 43s 701ms/step - loss: 0.2485 - accuracy: 0.9636 - val_loss: 0.6434 - val_accuracy: 0.9074\n",
            "Epoch 5/20\n",
            "61/61 [==============================] - 43s 705ms/step - loss: 0.3856 - accuracy: 0.9487 - val_loss: 0.6826 - val_accuracy: 0.9198\n",
            "Epoch 6/20\n",
            "61/61 [==============================] - 43s 706ms/step - loss: 0.1643 - accuracy: 0.9774 - val_loss: 0.4808 - val_accuracy: 0.9414\n",
            "Epoch 7/20\n",
            "61/61 [==============================] - 43s 703ms/step - loss: 0.1765 - accuracy: 0.9744 - val_loss: 0.6477 - val_accuracy: 0.9414\n",
            "Epoch 8/20\n",
            "61/61 [==============================] - 43s 703ms/step - loss: 0.2204 - accuracy: 0.9708 - val_loss: 0.9078 - val_accuracy: 0.9228\n",
            "Epoch 9/20\n",
            "61/61 [==============================] - 43s 703ms/step - loss: 0.2474 - accuracy: 0.9682 - val_loss: 0.9514 - val_accuracy: 0.9198\n",
            "Epoch 10/20\n",
            "61/61 [==============================] - 43s 697ms/step - loss: 0.2906 - accuracy: 0.9677 - val_loss: 1.0798 - val_accuracy: 0.8981\n",
            "Epoch 11/20\n",
            "61/61 [==============================] - 42s 695ms/step - loss: 0.2105 - accuracy: 0.9749 - val_loss: 0.6785 - val_accuracy: 0.9444\n",
            "Epoch 12/20\n",
            "61/61 [==============================] - 42s 695ms/step - loss: 0.1929 - accuracy: 0.9790 - val_loss: 0.5293 - val_accuracy: 0.9537\n",
            "Epoch 13/20\n",
            "61/61 [==============================] - 43s 699ms/step - loss: 0.1691 - accuracy: 0.9810 - val_loss: 0.6535 - val_accuracy: 0.9414\n",
            "Epoch 14/20\n",
            "61/61 [==============================] - 43s 697ms/step - loss: 0.2287 - accuracy: 0.9749 - val_loss: 0.7701 - val_accuracy: 0.8981\n",
            "Epoch 15/20\n",
            "61/61 [==============================] - 43s 697ms/step - loss: 0.2397 - accuracy: 0.9774 - val_loss: 0.6782 - val_accuracy: 0.9506\n",
            "Epoch 16/20\n",
            "61/61 [==============================] - 43s 697ms/step - loss: 0.1330 - accuracy: 0.9831 - val_loss: 0.5651 - val_accuracy: 0.9475\n",
            "Epoch 17/20\n",
            "61/61 [==============================] - 42s 693ms/step - loss: 0.1449 - accuracy: 0.9836 - val_loss: 0.5431 - val_accuracy: 0.9506\n",
            "Epoch 18/20\n",
            "61/61 [==============================] - 42s 696ms/step - loss: 0.1434 - accuracy: 0.9831 - val_loss: 0.8684 - val_accuracy: 0.9599\n",
            "Epoch 19/20\n",
            "61/61 [==============================] - 43s 697ms/step - loss: 0.1239 - accuracy: 0.9877 - val_loss: 0.8838 - val_accuracy: 0.9444\n",
            "Epoch 20/20\n",
            "61/61 [==============================] - 43s 705ms/step - loss: 0.2063 - accuracy: 0.9800 - val_loss: 0.7510 - val_accuracy: 0.9537\n",
            "model resnet152v2 trained and saved\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Found 1951 images belonging to 4 classes.\n",
            "Found 324 images belonging to 4 classes.\n",
            "Epoch 1/20\n",
            "61/61 [==============================] - 41s 677ms/step - loss: 1.8371 - accuracy: 0.7729 - val_loss: 0.5108 - val_accuracy: 0.8889\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 38s 629ms/step - loss: 0.6151 - accuracy: 0.8806 - val_loss: 1.3301 - val_accuracy: 0.8488\n",
            "Epoch 3/20\n",
            "61/61 [==============================] - 38s 626ms/step - loss: 0.6480 - accuracy: 0.8990 - val_loss: 0.4365 - val_accuracy: 0.9105\n",
            "Epoch 4/20\n",
            "61/61 [==============================] - 38s 624ms/step - loss: 0.4948 - accuracy: 0.9124 - val_loss: 0.4710 - val_accuracy: 0.9414\n",
            "Epoch 5/20\n",
            "61/61 [==============================] - 38s 626ms/step - loss: 0.5780 - accuracy: 0.9206 - val_loss: 1.0514 - val_accuracy: 0.8673\n",
            "Epoch 6/20\n",
            "61/61 [==============================] - 38s 625ms/step - loss: 0.6703 - accuracy: 0.9077 - val_loss: 1.5816 - val_accuracy: 0.8426\n",
            "Epoch 7/20\n",
            "61/61 [==============================] - 38s 629ms/step - loss: 0.8265 - accuracy: 0.9149 - val_loss: 0.5790 - val_accuracy: 0.9321\n",
            "Epoch 8/20\n",
            "61/61 [==============================] - 39s 634ms/step - loss: 0.3375 - accuracy: 0.9539 - val_loss: 0.5032 - val_accuracy: 0.9321\n",
            "Epoch 9/20\n",
            "61/61 [==============================] - 38s 624ms/step - loss: 0.4340 - accuracy: 0.9457 - val_loss: 0.4639 - val_accuracy: 0.9383\n",
            "Epoch 10/20\n",
            "61/61 [==============================] - 38s 629ms/step - loss: 0.3255 - accuracy: 0.9513 - val_loss: 0.5016 - val_accuracy: 0.9383\n",
            "Epoch 11/20\n",
            "61/61 [==============================] - 38s 625ms/step - loss: 0.3046 - accuracy: 0.9564 - val_loss: 0.4467 - val_accuracy: 0.9568\n",
            "Epoch 12/20\n",
            "61/61 [==============================] - 38s 628ms/step - loss: 0.4789 - accuracy: 0.9493 - val_loss: 0.5868 - val_accuracy: 0.9383\n",
            "Epoch 13/20\n",
            "61/61 [==============================] - 38s 624ms/step - loss: 0.3022 - accuracy: 0.9585 - val_loss: 0.3533 - val_accuracy: 0.9630\n",
            "Epoch 14/20\n",
            "61/61 [==============================] - 38s 629ms/step - loss: 0.2015 - accuracy: 0.9708 - val_loss: 0.3428 - val_accuracy: 0.9568\n",
            "Epoch 15/20\n",
            "61/61 [==============================] - 38s 624ms/step - loss: 0.5587 - accuracy: 0.9452 - val_loss: 0.9342 - val_accuracy: 0.9259\n",
            "Epoch 16/20\n",
            "61/61 [==============================] - 39s 635ms/step - loss: 0.4348 - accuracy: 0.9503 - val_loss: 0.5703 - val_accuracy: 0.9383\n",
            "Epoch 17/20\n",
            "61/61 [==============================] - 38s 624ms/step - loss: 0.3266 - accuracy: 0.9621 - val_loss: 0.6443 - val_accuracy: 0.9321\n",
            "Epoch 18/20\n",
            "61/61 [==============================] - 38s 625ms/step - loss: 0.5551 - accuracy: 0.9477 - val_loss: 0.6822 - val_accuracy: 0.9568\n",
            "Epoch 19/20\n",
            "61/61 [==============================] - 38s 624ms/step - loss: 0.4808 - accuracy: 0.9513 - val_loss: 1.7221 - val_accuracy: 0.8889\n",
            "Epoch 20/20\n",
            "61/61 [==============================] - 38s 625ms/step - loss: 0.3483 - accuracy: 0.9657 - val_loss: 0.7493 - val_accuracy: 0.9352\n",
            "model inceptionv3 trained and saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZA-VtLrgRgd"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}